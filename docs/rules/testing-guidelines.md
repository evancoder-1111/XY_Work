# 测试规范（Testing Guidelines）

## 1. 范围与目标（Scope & Goals）
- 单元测试、集成测试、端到端（E2E）测试覆盖核心路径
- 关键指标：稳定性、回归防护、可维护性
- **测试金字塔**：
  - 底层：单元测试（70%）- 快速、隔离、聚焦单一功能
  - 中层：集成测试（20%）- 验证组件间协作
  - 顶层：E2E测试（10%）- 模拟真实用户场景
- **持续质量保障**：
  - 测试前移：需求阶段即考虑测试策略
  - 测试左移：开发过程中进行持续测试
  - 测试右移：生产环境监控与反馈

## 2. 前端（Frontend）
- 框架：Vitest + Vue Test Utils
- 要点：
  - 组件渲染/交互用例；API 调用使用 MSW mock
  - 复杂列表与表单的边界用例（空态/错误态/极值）

## 3. 后端（Backend）
- 单元测试：JUnit 5 + Mockito
- 集成测试：Spring Boot Test + TestContainers（MySQL/Redis/外部依赖）
- 要点：
  - Service 业务分支与异常分支
  - Controller 接口契约、鉴权校验

## 4. 覆盖率（Coverage）
- 建议：行/分支 >= 70%（核心模块可更高）
- 覆盖率仅作参考，避免为达标而编写无意义测试

## 5. 测试数据（Test Data）
- 固定基准数据 + 动态工厂；清理隔离
- 脱敏样例，禁止真实敏感数据

## 6. CI 集成（CI Integration）
- PR 必跑测试；失败必修复或回退
- 产出 HTML/XML 报告；关键分支生成趋势图

## 7. 性能测试（Performance Testing）

### 7.1 性能测试标准
- **响应时间标准**：
  - 页面加载：首次内容渲染 < 2 秒
  - API 响应：95% 请求 < 500ms，99% 请求 < 1 秒
  - 数据库查询：复杂查询 < 100ms
- **并发处理标准**：
  - 核心业务接口：支持 100 QPS 稳定运行
  - 系统整体：支持 1000 并发用户
  - 峰值处理：支持正常负载的 2 倍峰值
- **资源消耗标准**：
  - CPU 使用率：峰值 < 70%
  - 内存使用率：稳定运行 < 60%
  - 数据库连接：最大连接数的 80% 以内

### 7.2 性能测试类型
- **负载测试**：逐步增加负载，确定系统性能瓶颈
- **压力测试**：持续高负载，验证系统稳定性和极限
- **耐久性测试**：长时间运行，检测内存泄漏和性能衰减
- **并发测试**：多用户同时操作，验证并发处理能力
- **吞吐量测试**：测量系统处理请求的最大能力

### 7.3 性能测试工具
- **前端性能**：Lighthouse, WebPageTest, Chrome DevTools
- **API 性能**：JMeter, Postman, k6, Artillery
- **数据库性能**：MySQL Explain, pgBadger, SQL Profiler
- **系统监控**：Prometheus + Grafana, Datadog, New Relic

### 7.4 性能优化流程
1. **性能基准建立**：确定当前性能基准指标
2. **测试执行**：运行性能测试并收集数据
3. **瓶颈分析**：识别性能瓶颈和问题点
4. **优化实施**：进行代码、配置或架构优化
5. **验证测试**：再次运行测试验证优化效果
6. **持续监控**：在生产环境持续监控性能指标

## 8. 测试用例设计（Test Case Design）

### 8.1 测试用例结构
- **测试用例 ID**：唯一标识符（如 TC-USER-001）
- **测试用例名称**：清晰描述测试目的
- **前置条件**：测试执行前需要满足的条件
- **测试步骤**：详细的操作步骤
- **预期结果**：期望的行为和输出
- **实际结果**：测试执行后的结果
- **状态**：通过/失败/阻塞
- **优先级**：P0/P1/P2（关键/重要/一般）

### 8.2 测试用例设计方法
- **等价类划分**：将输入数据划分为有效和无效等价类
- **边界值分析**：测试输入和输出的边界条件
- **因果图法**：分析输入条件之间的因果关系
- **决策表法**：基于条件组合生成测试用例
- **场景法**：基于用户场景设计测试用例
- **错误推测法**：基于经验推测可能的错误

### 8.3 测试用例管理
- **测试用例库**：使用 TestRail, JIRA 等工具管理
- **版本控制**：与代码版本保持一致
- **定期审查**：每季度审查并更新测试用例
- **覆盖率分析**：确保测试用例覆盖所有需求

## 9. 自动化测试策略（Automation Strategy）

### 9.1 自动化测试范围
- **适合自动化**：
  - 重复执行的测试（回归测试）
  - 数据驱动的测试（多组输入）
  - 性能和负载测试
  - 冒烟测试和关键路径测试
- **不适合自动化**：
  - 视觉设计和用户体验测试
  - 探索性测试
  - 一次性测试
  - 频繁变化的功能

### 9.2 自动化测试框架
- **前端自动化**：
  - 单元测试：Jest/Vitest, React Testing Library/Vue Test Utils
  - E2E测试：Cypress, Playwright, Puppeteer
- **后端自动化**：
  - 单元测试：JUnit, pytest, Mocha
  - API测试：RestAssured, SuperTest, requests
- **移动自动化**：
  - Appium, Detox, Espresso, XCUITest

### 9.3 自动化测试最佳实践
- **测试数据管理**：
  - 使用测试数据工厂生成测试数据
  - 每个测试独立且可重复
  - 测试后清理数据
- **测试隔离**：
  - 测试之间相互独立
  - 避免测试顺序依赖
  - 使用 mock/stub 隔离外部依赖
- **报告与监控**：
  - 生成详细的测试报告
  - 集成到 CI/CD 流程
  - 设置测试失败告警
- **维护策略**：
  - 定期更新和维护测试脚本
  - 重构复杂的测试代码
  - 移除过时的测试

## 10. 测试环境管理（Test Environment Management）

### 10.1 环境分类
- **开发环境**：开发人员使用，持续更新
- **测试环境**：QA 团队使用，稳定的测试环境
- **预生产环境**：生产环境的镜像，最终验证
- **生产环境**：实际用户使用的环境

### 10.2 环境配置
- **配置管理**：使用配置管理工具（如 Ansible, Terraform）
- **环境一致性**：所有环境配置保持一致
- **环境隔离**：不同环境之间严格隔离
- **自动化部署**：使用 CI/CD 工具自动化环境部署

### 10.3 环境维护
- **定期清理**：定期清理测试数据和日志
- **资源监控**：监控环境资源使用情况
- **环境恢复**：建立环境快速恢复机制
- **问题追踪**：记录和解决环境相关问题

## 11. 缺陷管理（Defect Management）

### 11.1 缺陷生命周期
- **发现**：识别并记录缺陷
- **分类**：根据严重性和优先级分类
- **分配**：分配给相关开发人员
- **修复**：开发人员修复缺陷
- **验证**：QA 验证缺陷是否已修复
- **关闭**：缺陷验证通过后关闭
- **拒绝/延期**：无法或暂不修复的缺陷

### 11.2 缺陷分类
- **严重性**：
  - 阻断（Blocker）：功能完全无法使用
  - 严重（Critical）：主要功能受影响
  - 一般（Major）：功能部分受影响
  - 轻微（Minor）：不影响主要功能
  - 建议（Trivial）：改进建议
- **优先级**：
  - P0：必须在发布前修复
  - P1：应在当前迭代修复
  - P2：可在下一迭代修复
  - P3：可在适当时候修复

### 11.3 缺陷报告
- **缺陷报告内容**：
  - 缺陷标题：简洁明了描述问题
  - 环境信息：操作系统、浏览器、版本等
  - 重现步骤：详细的操作步骤
  - 预期结果：期望的行为
  - 实际结果：观察到的问题
  - 附件：截图、日志、视频等
- **缺陷管理工具**：JIRA, Bugzilla, Mantis

## 12. 测试报告（Test Reports）

### 12.1 测试报告内容
- **测试摘要**：测试范围、执行情况、通过率
- **测试结果**：按模块和功能的测试结果
- **缺陷统计**：缺陷数量、严重程度分布
- **覆盖率统计**：代码覆盖率、需求覆盖率
- **性能指标**：响应时间、吞吐量等性能数据
- **风险评估**：已识别的风险和缓解措施
- **建议与结论**：改进建议和总体结论

### 12.2 测试报告类型
- **每日报告**：日常测试进展和问题
- **迭代报告**：迭代周期的测试总结
- **发布报告**：版本发布前的最终测试报告
- **性能测试报告**：详细的性能测试结果

### 12.3 报告最佳实践
- **数据可视化**：使用图表展示测试数据
- **简洁明了**：避免冗长，突出重点
- **及时性**：测试完成后及时生成报告
- **可追溯性**：与需求和缺陷保持关联

## 13. 测试最佳实践（Testing Best Practices）

### 13.1 测试原则
- **尽早测试**：在开发早期开始测试
- **全面测试**：覆盖功能、性能、安全等方面
- **重点测试**：重点关注核心功能和高风险模块
- **持续测试**：将测试集成到开发流程中
- **独立测试**：保持测试的独立性和客观性

### 13.2 常见问题与解决方案
- **测试覆盖率低**：优先覆盖核心功能，逐步提高覆盖率
- **测试执行慢**：优化测试脚本，并行执行测试
- **环境不稳定**：加强环境管理，建立环境监控
- **缺陷重复出现**：分析根本原因，加强回归测试
- **测试数据不足**：建立测试数据管理策略，使用数据生成工具

### 13.3 测试成熟度提升
- **评估当前成熟度**：使用测试成熟度模型评估
- **制定改进计划**：基于评估结果制定改进计划
- **培训与知识分享**：定期组织测试培训和经验分享
- **工具与流程优化**：持续优化测试工具和流程
- **度量与改进**：收集测试度量数据，持续改进

